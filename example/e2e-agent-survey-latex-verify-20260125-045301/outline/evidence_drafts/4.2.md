# Evidence draft: 4.2 Memory and retrieval (RAG)

## Evidence snippets (with provenance)
- (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs. Zhang2025Large (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
- (E-P0084-17fb12f5b7) In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0084#method)
- (E-P0131-c9781caf3b) SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability. Huang2025Retrieval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0131#limitations[1])
- (E-P0104-e294aeefb5) To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. Abbineni2025Muallm (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0104#key_results[1])
- (E-P0032-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0032#key_results[1])
- (E-P0131-4af0cf3c02) This study presents SAFE (system for accurate fact extraction and evaluation), an agent system that combines large language models with retrieval-augmented generation (RAG) to improve automated fact-checking of long-form COVID-19 misinformation. Huang2025Retrieval (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0131#key_results[1])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0166-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0166#key_results[1])
- (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
- (E-P0191-3e2348e239) Furthermore, we introduce SynAgent-RAG, a synthetic dataset to enable the proposed agent framework for small open-source LLMs (e.g., Llama-3-8B). Pham2025Agent (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0191#key_results[0])

## Definitions / setup

- Setup: Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Memory and retrieval (RAG)'.. Axes: evaluation protocol (datasets, metrics, human evaluation); compute and latency constraints; tool interface contract (schemas / protocols); tool selection / routing policy; sandboxing / permissions / observability. Verma2026Active Yu2026Agentic Tao2026Membox

## Claim candidates

- Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large
- In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. Kang2025Distilling
- SAFE demonstrates robust improvements in long-form COVID-19 fact-checking by addressing LLM limitations in consistency and explainability. Huang2025Retrieval
- To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. Abbineni2025Muallm
- Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta

## Concrete comparisons

- Axis: evaluation protocol (datasets, metrics, human evaluation); A: Agent frameworks / architectures: `P0166`, `P0167`, `P0177`; B: Memory / retrieval augmentation: `P0166`, `P0167`, `P0177`. Kang2025Distilling Zhang2025Large
  - A highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - A highlight: (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
  - B highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - B highlight: (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
- Axis: compute and latency constraints; A: Agent frameworks / architectures: `P0166`, `P0167`, `P0177`; B: Memory / retrieval augmentation: `P0166`, `P0167`, `P0177`. Kang2025Distilling Verma2026Active Tawosi2025Meta
  - A highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - A highlight: (E-P0166-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0166#key_results[1])
  - B highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - B highlight: (E-P0032-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[1])
- Axis: tool interface contract (schemas / protocols); A: Agent frameworks / architectures: `P0166`, `P0167`, `P0177`; B: Memory / retrieval augmentation: `P0166`, `P0167`, `P0177`. Kang2025Distilling Zhang2025Large
  - A highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - A highlight: (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
  - B highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - B highlight: (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
- Axis: tool selection / routing policy; A: Agent frameworks / architectures: `P0166`, `P0167`, `P0177`; B: Memory / retrieval augmentation: `P0166`, `P0167`, `P0177`. Kang2025Distilling Zhang2025Large
  - A highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - A highlight: (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
  - B highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - B highlight: (E-P0030-897bcc2f50) Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. Zhang2025Large (pointer: papers/paper_notes.jsonl:paper_id=P0030#key_results[0])
- Axis: sandboxing / permissions / observability; A: Agent frameworks / architectures: `P0166`, `P0167`, `P0177`; B: Memory / retrieval augmentation: `P0166`, `P0167`, `P0177`. Kang2025Distilling Verma2026Active Tawosi2025Meta
  - A highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - A highlight: (E-P0166-9abcf1bf8a) Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. Verma2026Active (pointer: papers/paper_notes.jsonl:paper_id=P0166#key_results[1])
  - B highlight: (E-P0084-dc7fe955d8) Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Kang2025Distilling (pointer: papers/paper_notes.jsonl:paper_id=P0084#key_results[1])
  - B highlight: (E-P0032-f36b515991) Our system introduces a novel Retrieval Augmented Generation (RAG) approach, Meta-RAG, where we utilize summaries to condense codebases by an average of 79.8\%, into a compact, structured, natural language representation. Tawosi2025Meta (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[1])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: SWE-bench; LTM; STM; GRPO; AgeMem; MEM; LoCoMo; AI-based; RAG; AutoCAD. Verma2026Active Yu2026Agentic Tao2026Membox Zhang2025Large

## Failures / limitations

- Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Yu2026Agentic
- This results in the failure to retrieve the relevant code of these fine-grained subtasks. Li2025Graphcodeagent
- To address this challenge, we propose GraphCodeAgent, a dual graph-guided LLM agent for retrieval-augmented repo-level code generation, bridging the gap between NL requirements and programming implementations. Li2025Graphcodeagent
- MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. Wu2025Meta

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- baseline choices and ablation evidence
