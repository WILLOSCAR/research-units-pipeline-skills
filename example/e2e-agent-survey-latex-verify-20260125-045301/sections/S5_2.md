A key trade-off is that coordination can improve coverage and robustness, yet it also introduces new failure modes (miscommunication, incentive misalignment, error amplification) and higher cost. Multi-agent systems extend the agent loop by adding communication and aggregation, with the hope that specialization and verification can reduce single-model brittleness, but the gains are meaningful only under an explicit coordination protocol [@Shen2024Small; @Wu2025Agents].

Most coordination schemes can be decomposed into three primitives: role assignment (who does what), communication protocol (what is exchanged), and aggregation rule (how outputs are combined). Small changes in these primitives can turn "multi-agent" from helpful verification into redundant chatter, which is why coordination results are difficult to compare unless the protocol details are stated explicitly [@Cui2025Toward; @Wu2025Agents]. Whereas simple ensembling aggregates independent answers, role-based coordination tries to create complementarity by constraining who explores, who critiques, and who verifies, which changes both the error model and the cost model [@Wu2025Agents].
Coordination papers are most comparable when they state role definitions, message formats, and aggregation rules as first-class evaluation metadata rather than as implementation details.

Training and evaluation frameworks for long-horizon coordination emphasize efficiency constraints. Multi-turn training settings highlight that coordination quality depends on asynchronous scheduling, batching, and tool integration, not just on the base models' reasoning ability [@Cao2025Skyrl; @Silva2025Agents].
The infrastructure layer can change coordination outcomes by changing latency and synchronization, so "algorithmic" comparisons need to control for these protocol-level confounds [@Cao2025Skyrl].

Tool- and memory-mediated coordination provides another angle: agents may coordinate by sharing tool state, selectively removing tools, or enforcing shared memory policies. Such interventions can be evaluated as controlled protocol changes that expose how coordination interacts with tool availability and how quickly failures propagate through the group [@Lumer2025Memtool; @Hu2023Avis].
Shared-state coordination also creates a natural place to enforce policies (e.g., tool gating and consistency checks), which can make the system more auditable than purely conversational coordination.

Tree-structured coordination and deliberation strategies highlight a complementary mechanism: rather than relying on a single trajectory, the system explores multiple branches and uses aggregation to select or verify candidates. This shifts the bottleneck to evaluation and selection, making scoring functions and stopping rules a key part of the coordination contract [@Ji2025Tree; @Cui2025Toward].
This style trades off breadth for accounting: tree search can reduce single-trajectory brittleness, whereas it can also behave like implicit ensembling if the protocol does not normalize the number of branches, verification calls, and tool invocations [@Ji2025Tree; @Li2025Draft].

A useful contrast is how coordination shares state. Some systems coordinate primarily through message passing (each agent maintains its own context), whereas others coordinate through shared tools or shared memory policies that enforce a common state and reduce divergence. These choices affect not only accuracy, but also failure propagation: shared-state designs can prevent inconsistent actions, but they can also amplify a single poisoned memory item across the group [@Lumer2025Memtool; @Hu2023Avis].

Evaluation remains the main constraint. Coordination can look strong when the benchmark rewards diversity of attempts, and it can look weak when the benchmark penalizes any disagreement without modeling uncertainty. Protocol-aware benchmarks and testing suites therefore matter as much as coordination algorithms, because they determine whether the observed gains reflect genuine complementarity or accidental protocol fit [@Silva2025Agents; @Hu2023Avis].
Many apparent coordination gains disappear once cost and disagreement are scored under a stricter protocol.

Domain-specific coordination examples illustrate that multi-agent benefits are often mediated by domain structure. In specialized settings (e.g., circuit optimization or geometry problem solving), coordination can represent decomposed subproblems and verification, but only if the communication format aligns with domain representations and constraints [@Ghose2025Orfs; @Zhao2025Achieving].

A limitation of many multi-agent reports is accounting: improvements are often reported without clear cost normalization (number of agents, turns, tool calls), which makes it hard to distinguish algorithmic gains from brute-force search or ensembling. In contrast to single-agent settings where cost is often approximated by token count, coordination costs include cross-agent communication, redundant tool calls, and verification overhead, so a "better" system may be worse under realistic deployment budgets unless accounting is explicit [@Li2025Draft; @Cao2025Skyrl].

Multi-agent coordination is best treated as a protocol layer that sits above tool interfaces and planning loops. The most useful comparisons specify roles, communication bandwidth, aggregation rules, and cost normalization, so that coordination gains can be interpreted as decision-relevant trade-offs rather than as artifacts of a particular prompting or infrastructure setup [@Shen2024Small; @Wu2025Agents; @Cui2025Toward; @Lumer2025Memtool].
This highlights why coordination results often fail to transfer: the coordination contract, not the base model, is what changes between implementations.
