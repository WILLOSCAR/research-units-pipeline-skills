{"section_id": "3", "section_title": "Foundations & Interfaces", "subsections": [{"sub_id": "3.1", "title": "Agent loop and action spaces"}, {"sub_id": "3.2", "title": "Tool interfaces and orchestration"}], "synthesis_mode": "tradeoff_matrix", "synthesis_preview": ["Synthesize by comparing approaches along a small trade-off matrix (axes + evaluation protocol), not by listing papers.", "Keep contrasts decision-relevant (reliability/cost/safety) and reuse consistent evaluation anchors across H3s."], "throughline": ["Pin scope to goal: agent survey (LLM agents) LaTeX survey.", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup.", "Compare approaches along: evaluation protocol (datasets / metrics / human).", "Compare approaches along: efficiency / compute.", "Compare approaches along: failure modes / limitations."], "key_contrasts": ["evaluation", "tool interfaces"], "lead_paragraph_plan": ["Para 1: state the chapter’s role and the decision-relevant comparison axes (no new facts).", "Para 2: preview the H3 subsections and how they decompose the chapter question.", "Para 3 (optional): highlight evaluation anchors + recurrent limitations that will recur across H3s."], "bridge_terms": ["benchmarks/metrics", "compute", "function calling", "tool schema", "routing", "sandbox", "observability"], "generated_at": "2026-01-19T12:09:28"}
{"section_id": "4", "section_title": "Core Components (Planning + Memory)", "subsections": [{"sub_id": "4.1", "title": "Planning and reasoning loops"}, {"sub_id": "4.2", "title": "Memory and retrieval (RAG)"}], "synthesis_mode": "clusters", "synthesis_preview": ["Synthesize by contrasting 2–3 clusters of approaches and making the trade-offs explicit (not a per-paper summary).", "Use explicit connectors (however/therefore/building on) to keep paragraphs from becoming islands."], "throughline": ["Pin scope to goal: agent survey (LLM agents) LaTeX survey.", "Compare approaches along: control loop design (planner / executor, search).", "Compare approaches along: deliberation method (CoT / ToT / MCTS).", "Compare approaches along: action grounding (tool calls vs environment actions).", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup."], "key_contrasts": ["planning/control loop", "memory/retrieval"], "lead_paragraph_plan": ["Para 1: state the chapter’s role and the decision-relevant comparison axes (no new facts).", "Para 2: preview the H3 subsections and how they decompose the chapter question.", "Para 3 (optional): highlight evaluation anchors + recurrent limitations that will recur across H3s."], "bridge_terms": ["planner/executor", "search", "deliberation", "action grounding", "retrieval", "index", "write policy", "long-term memory"], "generated_at": "2026-01-19T12:09:28"}
{"section_id": "5", "section_title": "Learning, Adaptation & Coordination", "subsections": [{"sub_id": "5.1", "title": "Self-improvement and adaptation"}, {"sub_id": "5.2", "title": "Multi-agent coordination"}], "synthesis_mode": "clusters", "synthesis_preview": ["Synthesize by contrasting 2–3 clusters of approaches and making the trade-offs explicit (not a per-paper summary).", "Use explicit connectors (however/therefore/building on) to keep paragraphs from becoming islands."], "throughline": ["Pin scope to goal: agent survey (LLM agents) LaTeX survey.", "Compare approaches along: training signal (SFT / preference / RL).", "Compare approaches along: data synthesis + evaluator / reward.", "Compare approaches along: generalization + regression control.", "Compare approaches along: mechanism / architecture.", "Compare approaches along: data / training setup."], "key_contrasts": ["learning/feedback", "coordination"], "lead_paragraph_plan": ["Para 1: state the chapter’s role and the decision-relevant comparison axes (no new facts).", "Para 2: preview the H3 subsections and how they decompose the chapter question.", "Para 3 (optional): highlight evaluation anchors + recurrent limitations that will recur across H3s."], "bridge_terms": ["preference", "reward", "feedback", "self-improvement", "roles", "communication", "debate", "aggregation", "stability"], "generated_at": "2026-01-19T12:09:28"}
{"section_id": "6", "section_title": "Evaluation & Risks", "subsections": [{"sub_id": "6.1", "title": "Benchmarks and evaluation protocols"}, {"sub_id": "6.2", "title": "Safety, security, and governance"}], "synthesis_mode": "tradeoff_matrix", "synthesis_preview": ["Synthesize by comparing approaches along a small trade-off matrix (axes + evaluation protocol), not by listing papers.", "Keep contrasts decision-relevant (reliability/cost/safety) and reuse consistent evaluation anchors across H3s."], "throughline": ["Pin scope to goal: agent survey (LLM agents) LaTeX survey.", "Compare approaches along: tool interface (function calling, schemas, protocols).", "Compare approaches along: tool selection / routing policy.", "Compare approaches along: sandboxing / permissions / observability.", "Compare approaches along: task suites (web / code / embodied / tools).", "Compare approaches along: metrics (success, cost, reliability, safety)."], "key_contrasts": ["tool interfaces", "security"], "lead_paragraph_plan": ["Para 1: state the chapter’s role and the decision-relevant comparison axes (no new facts).", "Para 2: preview the H3 subsections and how they decompose the chapter question.", "Para 3 (optional): highlight evaluation anchors + recurrent limitations that will recur across H3s."], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability", "benchmarks", "threat model", "prompt/tool injection", "monitoring", "guardrails"], "generated_at": "2026-01-19T12:09:28"}
