{"sub_id": "3.1", "title": "Agent loop and action spaces", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Agent loop and action spaces highlights a tension around mechanism / architecture and data / training setup, motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Agent loop and action spaces'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["mechanism / architecture", "data / training setup", "evaluation protocol (datasets / metrics / human)", "efficiency / compute", "failure modes / limitations"], "bridge_terms": ["benchmarks/metrics", "compute"], "contrast_hook": "evaluation", "tension_statement": "In Agent loop and action spaces, a practical tension is expressivity versus control: richer interfaces expand capability but make behavior harder to constrain and verify.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "training signal / supervision", "failure modes / limitations"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0149", "P0150", "P0158", "P0008", "P0021", "P0022", "P0058", "P0070"], "bibkeys": ["Song2026Envscaler", "Zhang2026Evoroute", "Xi2026Toolgym", "Luo2025Large", "Gasmi2025Bridging", "Kim2025Bridging", "Li2025Agentswift", "Fumero2025Cybersleuth"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0149", "P0158", "P0085", "P0090", "P0117"], "bibkeys": ["Song2026Envscaler", "Xi2026Toolgym", "Liu2025Mcpagentbench", "Ghose2025Orfs", "Fang2025Should"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0022", "P0058", "P0197", "P0001"], "bibkeys": ["Kim2025Bridging", "Li2025Agentswift", "Xu2025Exemplar", "Yao2022React"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Tool-use and function calling", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Tool-use and function calling vs Agent frameworks / architectures", "use_clusters": ["Tool-use and function calling"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Tool-use and function calling", "data / training setup", "interface contract", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Tool-use and function calling"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Tool-use and function calling", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Tool-use and function calling"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Tool-use and function calling", "multiple citations in one paragraph", "axes: mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Tool-use and function calling along mechanism / architecture, data / training setup, evaluation protocol (datasets / metrics / human), efficiency / compute, failure modes / limitations", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "3.2", "title": "Tool interfaces and orchestration", "section_id": "3", "section_title": "Foundations & Interfaces", "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Tool interfaces and orchestration highlights a tension around tool interface (function calling, schemas, protocols) and tool selection / routing policy, motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Tool interfaces and orchestration'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["tool interface (function calling, schemas, protocols)", "tool selection / routing policy", "sandboxing / permissions / observability", "mechanism / architecture", "data / training setup"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability"], "contrast_hook": "tool interfaces", "tension_statement": "In Tool interfaces and orchestration, a practical tension is expressivity versus control: richer interfaces expand capability but make behavior harder to constrain and verify.", "evaluation_anchor_minimal": {"task": "attack/defense evaluation", "metric": "attack success rate", "constraint": "policy/sandbox setting"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0151", "P0157", "P0019", "P0032", "P0039", "P0076", "P0088", "P0090"], "bibkeys": ["Hao2026From", "Xuan2026Confidence", "Jia2025Autotool", "Zhou2025Self", "Cheng2025Your", "Mohammadi2025Evaluation", "Lumer2025Memtool", "Ghose2025Orfs"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0151", "P0157", "P0019", "P0039", "P0086", "P0088", "P0090", "P0113"], "bibkeys": ["Hao2026From", "Xuan2026Confidence", "Jia2025Autotool", "Cheng2025Your", "Dong2025Bench", "Lumer2025Memtool", "Ghose2025Orfs", "Liu2025Toolscope"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0076", "P0086", "P0168"], "bibkeys": ["Mohammadi2025Evaluation", "Dong2025Bench", "Chen2025Agentguard"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Tool interfaces and orchestration drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Tool-use and function calling", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Tool-use and function calling vs Agent frameworks / architectures", "use_clusters": ["Tool-use and function calling"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Tool-use and function calling", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Tool-use and function calling"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Tool-use and function calling", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Tool-use and function calling"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Tool-use and function calling", "multiple citations in one paragraph", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Tool-use and function calling along tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, mechanism / architecture, data / training setup", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Tool-use and function calling", "Evaluation / benchmark-focused works"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "4.1", "title": "Planning and reasoning loops", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?", "thesis": "In Planning and reasoning loops, differences in control loop design (planner / executor, search) and deliberation method (CoT / ToT / MCTS) frequently imply different evaluation setups, so the key is to compare under consistent protocols where possible.", "scope_rule": {"include": ["Core topics directly relevant to 'Planning and reasoning loops'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["control loop design (planner / executor, search)", "deliberation method (CoT / ToT / MCTS)", "action grounding (tool calls vs environment actions)", "mechanism / architecture", "data / training setup"], "bridge_terms": ["planner/executor", "search", "deliberation", "action grounding"], "contrast_hook": "planning/control loop", "tension_statement": "In Planning and reasoning loops, a practical tension is expressivity versus control: richer interfaces expand capability but make behavior harder to constrain and verify.", "evaluation_anchor_minimal": {"task": "web/navigation tasks", "metric": "success rate", "constraint": "latency and budget"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0012", "P0022", "P0023", "P0030", "P0065", "P0078", "P0093", "P0098"], "bibkeys": ["Zhou2025Reasoning", "Kim2025Bridging", "Nakano2025Guided", "Hatalis2025Review", "Silva2025Agents", "Mudur2025Feabench", "Hong2025Planning", "Choi2025Reactree"]}, {"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0012", "P0022", "P0030", "P0065", "P0098", "P0114", "P0162", "P0173"], "bibkeys": ["Zhou2025Reasoning", "Kim2025Bridging", "Hatalis2025Review", "Silva2025Agents", "Choi2025Reactree", "Hu2025Training", "Kiruluta2025Novel", "Rosario2025Architecting"]}, {"label": "Control / conditioning interfaces", "rationale": "Grouped by keyword tag `control` from titles (bootstrap).", "paper_ids": ["P0022", "P0098", "P0181"], "bibkeys": ["Kim2025Bridging", "Choi2025Reactree", "Wu2025Agents"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Planning / reasoning loops"], "rq": "Which design choices in Planning and reasoning loops drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Planning / reasoning loops", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Planning / reasoning loops as baseline", "use_clusters": ["Planning / reasoning loops"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Planning / reasoning loops", "data / training setup", "interface contract", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Planning / reasoning loops"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Planning / reasoning loops"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Agent frameworks / architectures", "contrast with Planning / reasoning loops", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Agent frameworks / architectures vs Planning / reasoning loops", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Planning / reasoning loops vs Agent frameworks / architectures", "multiple citations in one paragraph", "axes: control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Planning / reasoning loops vs Agent frameworks / architectures along control loop design (planner / executor, search), deliberation method (CoT / ToT / MCTS), action grounding (tool calls vs environment actions), mechanism / architecture, data / training setup", "use_clusters": ["Planning / reasoning loops", "Agent frameworks / architectures", "Control / conditioning interfaces"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Planning / reasoning loops", "Agent frameworks / architectures", "Control / conditioning interfaces"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Planning / reasoning loops", "Agent frameworks / architectures", "Control / conditioning interfaces"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "4.2", "title": "Memory and retrieval (RAG)", "section_id": "4", "section_title": "Core Components (Planning + Memory)", "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Memory and retrieval (RAG) highlights a tension around memory type (episodic / semantic / scratchpad) and retrieval source + index (docs / web / logs), motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Memory and retrieval (RAG)'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["memory type (episodic / semantic / scratchpad)", "retrieval source + index (docs / web / logs)", "write / update / forgetting policy", "mechanism / architecture", "data / training setup"], "bridge_terms": ["retrieval", "index", "write policy", "long-term memory"], "contrast_hook": "memory/retrieval", "tension_statement": "In Memory and retrieval (RAG), the core tension is persistence versus freshness: retaining more context helps long-horizon tasks but raises staleness, contamination, and verification challenges.", "evaluation_anchor_minimal": {"task": "web/navigation tasks", "metric": "success rate", "constraint": "latency and budget"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0146", "P0147", "P0156", "P0029", "P0058", "P0082", "P0088", "P0089"], "bibkeys": ["Verma2026Active", "Yu2026Agentic", "Tao2026Membox", "Shi2025Progent", "Li2025Agentswift", "Zhang2025Large", "Lumer2025Memtool", "Wu2025Meta"]}, {"label": "Memory / retrieval augmentation", "rationale": "Grouped by keyword tag `memory` from titles (bootstrap).", "paper_ids": ["P0146", "P0147", "P0156", "P0028", "P0082", "P0088", "P0089", "P0111"], "bibkeys": ["Verma2026Active", "Yu2026Agentic", "Tao2026Membox", "Tawosi2025Meta", "Zhang2025Large", "Lumer2025Memtool", "Wu2025Meta", "Ye2025Task"]}, {"label": "Code agents / software tasks", "rationale": "Grouped by keyword tag `code` from titles (bootstrap).", "paper_ids": ["P0028", "P0029", "P0205"], "bibkeys": ["Tawosi2025Meta", "Shi2025Progent", "Li2025Graphcodeagent"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Memory and retrieval (RAG) drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Memory / retrieval augmentation", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Memory / retrieval augmentation vs Agent frameworks / architectures", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Memory / retrieval augmentation", "data / training setup", "interface contract", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Memory / retrieval augmentation", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Memory / retrieval augmentation"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Memory / retrieval augmentation", "multiple citations in one paragraph", "axes: memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Memory / retrieval augmentation along memory type (episodic / semantic / scratchpad), retrieval source + index (docs / web / logs), write / update / forgetting policy, mechanism / architecture, data / training setup", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Code agents / software tasks"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Code agents / software tasks"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Memory / retrieval augmentation", "Code agents / software tasks"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "5.1", "title": "Self-improvement and adaptation", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Self-improvement and adaptation methods emphasize training signal (SFT / preference / RL) and data synthesis + evaluator / reward trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Self-improvement and adaptation'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["training signal (SFT / preference / RL)", "data synthesis + evaluator / reward", "generalization + regression control", "mechanism / architecture", "data / training setup"], "bridge_terms": ["preference", "reward", "feedback", "self-improvement"], "contrast_hook": "learning/feedback", "tension_statement": "A central tension in Self-improvement and adaptation is the trade-off between training signal (SFT / preference / RL), data synthesis + evaluator / reward and what can be evaluated reliably under realistic constraints.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0048", "P0150", "P0031", "P0032", "P0050", "P0051", "P0059", "P0073"], "bibkeys": ["Li2026Autonomous", "Zhang2026Evoroute", "Xia2025Sand", "Zhou2025Self", "Van2025Survey", "Lidayan2025Abbel", "Belle2025Agents", "He2025Enabling"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0059", "P0001"], "bibkeys": ["Belle2025Agents", "Yao2022React"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0050", "P0040"], "bibkeys": ["Van2025Survey", "Du2024Anytool"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Planning / reasoning loops", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Planning / reasoning loops vs Agent frameworks / architectures", "use_clusters": ["Planning / reasoning loops"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Planning / reasoning loops", "data / training setup", "interface contract", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Planning / reasoning loops"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Planning / reasoning loops", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Planning / reasoning loops"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Planning / reasoning loops", "multiple citations in one paragraph", "axes: training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Planning / reasoning loops along training signal (SFT / preference / RL), data synthesis + evaluator / reward, generalization + regression control, mechanism / architecture, data / training setup", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Planning / reasoning loops", "Tool-use and function calling"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "5.2", "title": "Multi-agent coordination", "section_id": "5", "section_title": "Learning, Adaptation & Coordination", "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Multi-agent coordination highlights a tension around communication protocol + role assignment and aggregation (vote / debate / referee), motivating a protocol-aware synthesis rather than per-paper summaries.", "scope_rule": {"include": ["Core topics directly relevant to 'Multi-agent coordination'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["communication protocol + role assignment", "aggregation (vote / debate / referee)", "stability (collusion, mode collapse, incentives)", "mechanism / architecture", "data / training setup"], "bridge_terms": ["roles", "communication", "debate", "aggregation", "stability"], "contrast_hook": "coordination", "tension_statement": "In Multi-agent coordination, a practical tension is expressivity versus control: richer interfaces expand capability but make behavior harder to constrain and verify.", "evaluation_anchor_minimal": {"task": "agent benchmark tasks", "metric": "success rate", "constraint": "budget/cost model"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0033", "P0065", "P0106", "P0118", "P0161", "P0164", "P0171", "P0179"], "bibkeys": ["Sarkar2025Survey", "Silva2025Agents", "Cao2025Skyrl", "Li2025What", "Hao2025Multi", "Papadakis2025Atlas", "Liu2025Aligning", "Einwiller2025Benevolent"]}, {"label": "Multi-agent coordination", "rationale": "Grouped by keyword tag `multi-agent` from titles (bootstrap).", "paper_ids": ["P0065", "P0164", "P0181", "P0187", "P0188", "P0217"], "bibkeys": ["Silva2025Agents", "Papadakis2025Atlas", "Wu2025Agents", "Chuang2025Debate", "Li2025Draft", "Zahedifar2025Agent"]}, {"label": "Planning / reasoning loops", "rationale": "Grouped by keyword tag `planning` from titles (bootstrap).", "paper_ids": ["P0065", "P0181", "P0188"], "bibkeys": ["Silva2025Agents", "Wu2025Agents", "Li2025Draft"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Multi-agent coordination drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Multi-agent coordination", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Multi-agent coordination vs Agent frameworks / architectures", "use_clusters": ["Multi-agent coordination"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Multi-agent coordination", "data / training setup", "interface contract", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Multi-agent coordination"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Multi-agent coordination", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Multi-agent coordination"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Multi-agent coordination", "multiple citations in one paragraph", "axes: communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Multi-agent coordination along communication protocol + role assignment, aggregation (vote / debate / referee), stability (collusion, mode collapse, incentives), mechanism / architecture, data / training setup", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Multi-agent coordination", "Planning / reasoning loops"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "6.1", "title": "Benchmarks and evaluation protocols", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Benchmarks and evaluation protocols methods emphasize tool interface (function calling, schemas, protocols) and tool selection / routing policy trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Benchmarks and evaluation protocols'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["tool interface (function calling, schemas, protocols)", "tool selection / routing policy", "sandboxing / permissions / observability", "task suites (web / code / embodied / tools)", "metrics (success, cost, reliability, safety)"], "bridge_terms": ["function calling", "tool schema", "routing", "sandbox", "observability", "benchmarks"], "contrast_hook": "tool interfaces", "tension_statement": "In Benchmarks and evaluation protocols, a practical tension is expressivity versus control: richer interfaces expand capability but make behavior harder to constrain and verify.", "evaluation_anchor_minimal": {"task": "code tasks", "metric": "test pass rate / success", "constraint": "sandbox and budget"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "compute / cost (train/infer)", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0013", "P0154", "P0006", "P0034", "P0035", "P0036", "P0037", "P0050"], "bibkeys": ["Kim2026Beyond", "Liu2026Agents", "Plaat2025Agentic", "Ji2025Taxonomy", "Chen2025Towards", "Hadeliya2025When", "Agrawal2025Language", "Van2025Survey"]}, {"label": "Evaluation / benchmark-focused works", "rationale": "Grouped by keyword tag `evaluation` from titles (bootstrap).", "paper_ids": ["P0013", "P0034", "P0035", "P0076", "P0083", "P0096", "P0180", "P0189"], "bibkeys": ["Kim2026Beyond", "Ji2025Taxonomy", "Chen2025Towards", "Mohammadi2025Evaluation", "Zhang2025Security", "Fu2025Eval", "Zhang2025Buildbench", "Zhang2025Datascibench"]}, {"label": "Safety / security / guardrails", "rationale": "Grouped by keyword tag `security` from titles (bootstrap).", "paper_ids": ["P0036", "P0083", "P0096", "P0214", "P0120"], "bibkeys": ["Hadeliya2025When", "Zhang2025Security", "Fu2025Eval", "Zhang2025Agents", "Zhang2024Agent"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Benchmarks and evaluation protocols drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Evaluation / benchmark-focused works", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Evaluation / benchmark-focused works vs Agent frameworks / architectures", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Evaluation / benchmark-focused works", "data / training setup", "interface contract", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Evaluation / benchmark-focused works", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Evaluation / benchmark-focused works"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Evaluation / benchmark-focused works", "multiple citations in one paragraph", "axes: tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Evaluation / benchmark-focused works along tool interface (function calling, schemas, protocols), tool selection / routing policy, sandboxing / permissions / observability, task suites (web / code / embodied / tools), metrics (success, cost, reliability, safety)", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Evaluation / benchmark-focused works", "Safety / security / guardrails"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
{"sub_id": "6.2", "title": "Safety, security, and governance", "section_id": "6", "section_title": "Evaluation & Risks", "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?", "thesis": "Safety, security, and governance methods emphasize threat model (prompt / tool injection, exfiltration) and defense surface (policy, sandbox, monitoring) trade-offs, but synthesis is clearest when claims are tied to explicit evaluation settings and reporting conventions.", "scope_rule": {"include": ["Core topics directly relevant to 'Safety, security, and governance'."], "exclude": [], "notes": "If you include an out-of-scope paper as a bridge, state the reason in 1 sentence and keep it secondary."}, "axes": ["threat model (prompt / tool injection, exfiltration)", "defense surface (policy, sandbox, monitoring)", "security evaluation protocol", "mechanism / architecture", "data / training setup"], "bridge_terms": ["threat model", "prompt/tool injection", "monitoring", "guardrails"], "contrast_hook": "security", "tension_statement": "In Safety, security, and governance, a practical tension is expressivity versus control: richer interfaces expand capability but make behavior harder to constrain and verify.", "evaluation_anchor_minimal": {"task": "attack/defense evaluation", "metric": "attack success rate", "constraint": "policy/sandbox setting"}, "required_evidence_fields": ["benchmarks/datasets", "metrics / human-eval protocol", "training signal / supervision", "threat model", "defense surface"], "clusters": [{"label": "Agent frameworks / architectures", "rationale": "Grouped by keyword tag `agents` from titles (bootstrap).", "paper_ids": ["P0012", "P0021", "P0036", "P0052", "P0053", "P0067", "P0083", "P0096"], "bibkeys": ["Zhou2025Reasoning", "Gasmi2025Bridging", "Hadeliya2025When", "Luo2025Agrail", "Sha2025Agent", "Bonagiri2025Check", "Zhang2025Security", "Fu2025Eval"]}, {"label": "Safety / security / guardrails", "rationale": "Grouped by keyword tag `security` from titles (bootstrap).", "paper_ids": ["P0021", "P0036", "P0052", "P0053", "P0067", "P0083", "P0096", "P0117"], "bibkeys": ["Gasmi2025Bridging", "Hadeliya2025When", "Luo2025Agrail", "Sha2025Agent", "Bonagiri2025Check", "Zhang2025Security", "Fu2025Eval", "Fang2025Should"]}, {"label": "Tool-use and function calling", "rationale": "Grouped by keyword tag `tool-use` from titles (bootstrap).", "paper_ids": ["P0083", "P0117", "P0207"], "bibkeys": ["Zhang2025Security", "Fang2025Should", "An2025Ipiguard"]}], "paragraph_plan": [{"para": 1, "argument_role": "setup_thesis", "intent": "Define scope, setup, and the subsection thesis (no pipeline jargon).", "focus": ["scope boundary", "key definitions", "thesis vs neighboring subsections"], "connector_to_prev": "", "connector_phrase": "", "use_clusters": ["Agent frameworks / architectures"], "rq": "Which design choices in Safety, security, and governance drive the major trade-offs, and how are those trade-offs measured?"}, {"para": 2, "argument_role": "mechanism_cluster_A", "intent": "Explain cluster A: core mechanism/architecture and what decision it makes in the agent loop.", "focus": ["cluster: Agent frameworks / architectures", "mechanism / architecture", "assumptions"], "connector_to_prev": "grounding", "connector_phrase": "Grounding: Agent frameworks / architectures as baseline", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 3, "argument_role": "implementation_cluster_A", "intent": "Cluster A implementation details: data/training signals and interface contract (tools/memory) that constrain behavior.", "focus": ["cluster: Agent frameworks / architectures", "data / training setup", "interface contract", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Elaboration: interface + training assumptions", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 4, "argument_role": "evaluation_cluster_A", "intent": "Cluster A evaluation/trade-offs: where it works, costs (compute/latency), and typical failure modes.", "focus": ["cluster: Agent frameworks / architectures", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation lens: protocol + failure modes", "use_clusters": ["Agent frameworks / architectures"]}, {"para": 5, "argument_role": "contrast_cluster_B", "intent": "Explain cluster B (contrast with A): core mechanism/architecture and what it optimizes for.", "focus": ["cluster: Safety / security / guardrails", "contrast with Agent frameworks / architectures", "mechanism / architecture"], "connector_to_prev": "contrast", "connector_phrase": "Contrast: Safety / security / guardrails vs Agent frameworks / architectures", "use_clusters": ["Safety / security / guardrails"]}, {"para": 6, "argument_role": "implementation_cluster_B", "intent": "Cluster B implementation details: data/training and interface assumptions (mirror A for comparability).", "focus": ["cluster: Safety / security / guardrails", "data / training setup", "interface contract", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "elaboration", "connector_phrase": "Implementation contrast: assumptions shift", "use_clusters": ["Safety / security / guardrails"]}, {"para": 7, "argument_role": "evaluation_cluster_B", "intent": "Cluster B evaluation/trade-offs: where it works, costs, and failure modes (mirror A).", "focus": ["cluster: Safety / security / guardrails", "evaluation anchor", "efficiency", "failure modes"], "connector_to_prev": "evaluation", "connector_phrase": "Evaluation contrast: apples-to-apples where possible", "use_clusters": ["Safety / security / guardrails"]}, {"para": 8, "argument_role": "cross_paper_synthesis", "intent": "Cross-paper synthesis: compare clusters along the main axes (include >=2 citations in one paragraph).", "focus": ["compare Agent frameworks / architectures vs Safety / security / guardrails", "multiple citations in one paragraph", "axes: threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup"], "connector_to_prev": "synthesis", "connector_phrase": "Synthesis: Agent frameworks / architectures vs Safety / security / guardrails along threat model (prompt / tool injection, exfiltration), defense surface (policy, sandbox, monitoring), security evaluation protocol, mechanism / architecture, data / training setup", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Tool-use and function calling"]}, {"para": 9, "argument_role": "decision_guidance", "intent": "Decision guidance: when to choose which route (criteria + evaluation signals + engineering constraints).", "focus": ["decision checklist", "evaluation protocol", "practical constraints"], "connector_to_prev": "consequence", "connector_phrase": "Implication: decision checklist", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Tool-use and function calling"]}, {"para": 10, "argument_role": "limitations_open_questions", "intent": "Limitations + verification targets; end with a concrete open question to hand off.", "focus": ["limitations", "evidence mode: provisional", "what needs verification", "open question"], "connector_to_prev": "limitations", "connector_phrase": "Limitations: verification targets", "use_clusters": ["Agent frameworks / architectures", "Safety / security / guardrails", "Tool-use and function calling"], "policy": "Use conservative language; avoid strong conclusions; prefer questions-to-answer + explicit evidence gaps list."}], "evidence_level_summary": {"fulltext": 0, "abstract": 18, "title": 0}, "generated_at": "2026-01-19T12:09:28"}
