# Evidence draft: 5.1 Self-improvement and adaptation

## Evidence snippets (with provenance)
- (E-P0048-67ea29ce26) We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Li2026Autonomous (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0048#method)
- (E-P0165-1063eee7ce) However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. Zhao2025Achieving (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0165#key_results[0])
- (E-P0040-4da9e4ae32) We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. Du2024Anytool (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0040#limitations[1])
- (E-P0032-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0032#key_results[0])
- (E-P0048-9980bf7642) Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Li2026Autonomous (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0048#key_results[1])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0040-d5c234444e) Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. Du2024Anytool (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0040#key_results[0])
- (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
- (E-P0031-6273763a98) Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches. Xia2025Sand (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0031#key_results[0])
- (E-P0048-499402e2fb) We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Li2026Autonomous (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0048#key_results[0])

## Definitions / setup

- Setup: Which design choices in Self-improvement and adaptation drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Self-improvement and adaptation'.. Axes: training signal (SFT / preference / RL); data synthesis + evaluator / reward; generalization + regression control; mechanism / architecture; data / training setup. Li2026Autonomous Zhang2026Evoroute Xia2025Sand

## Claim candidates

- We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Li2026Autonomous
- However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. Zhao2025Achieving
- We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. Du2024Anytool
- Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self
- Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Li2026Autonomous

## Concrete comparisons

- Axis: training signal (SFT / preference / RL); A: Agent frameworks / architectures: `P0048`, `P0150`, `P0031`; B: Planning / reasoning loops: `P0059`, `P0001`. Zhou2025Self Zhang2026Evoroute Yao2022React
  - A highlight: (E-P0032-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[0])
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: data synthesis + evaluator / reward; A: Agent frameworks / architectures: `P0048`, `P0150`, `P0031`; B: Planning / reasoning loops: `P0059`, `P0001`. Zhou2025Self Zhang2026Evoroute Yao2022React
  - A highlight: (E-P0032-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[0])
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: generalization + regression control; A: Agent frameworks / architectures: `P0048`, `P0150`, `P0031`; B: Planning / reasoning loops: `P0059`, `P0001`. Zhang2026Evoroute Zhou2025Self Yao2022React
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - A highlight: (E-P0032-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[0])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: mechanism / architecture; A: Agent frameworks / architectures: `P0048`, `P0150`, `P0031`; B: Planning / reasoning loops: `P0059`, `P0001`. Zhang2026Evoroute Zhou2025Self Yao2022React
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - A highlight: (E-P0032-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[0])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- Axis: data / training setup; A: Agent frameworks / architectures: `P0048`, `P0150`, `P0031`; B: Planning / reasoning loops: `P0059`, `P0001`. Zhou2025Self Zhang2026Evoroute Yao2022React
  - A highlight: (E-P0032-2e6956a116) Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data. Zhou2025Self (pointer: papers/paper_notes.jsonl:paper_id=P0032#key_results[0])
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - B highlight: (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (pointer: papers/paper_notes.jsonl:paper_id=P0001#key_results[0])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: DeepSeek-V3; LLMs; GAIA; EvoRoute; BrowseComp; SAND; ReAct-style; TauBench; FMs; MatSci. Li2026Autonomous Zhang2026Evoroute Xia2025Sand Zhou2025Self

## Failures / limitations

- Analysis of failure modes reveals characteristic patterns across models, with the multi-agent configuration substantially reducing implementation errors and hallucinations compared to simpler architectures. Li2026Autonomous
- We formalize this challenge as the \textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. Zhang2026Evoroute
- The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks. Zhou2025Self
- We assess the early successes of foundation models and identify persistent limitations, including challenges in generalizability, interpretability, data imbalance, safety concerns, and limited multimodal fusion. Van2025Survey

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- training data and supervision signal
- baseline choices and ablation evidence
