# Evidence draft: 3.1 Agent loop and action spaces

## Evidence snippets (with provenance)
- (E-P0022-9d9d60644a) We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). Kim2025Bridging (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0022#method)
- (E-P0165-1063eee7ce) However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. Zhao2025Achieving (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0165#key_results[0])
- (E-P0085-f7a14123f9) To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. Liu2025Mcpagentbench (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0085#limitations[1])
- (E-P0058-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
- (E-P0070-c8c4670812) We benchmark four agent architectures and six LLM backends on 20 incident scenarios of increasing complexity, identifying CyberSleuth as the best-performing design. Fumero2025Cybersleuth (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0070#key_results[0])
- (E-P0081-4b027dfb27) We evaluate GiGPO on challenging agent benchmarks, including ALFWorld and WebShop, as well as tool-integrated reasoning on search-augmented QA tasks, using Qwen2.5-1.5B/3B/7B-Instruct. Feng2025Group (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0081#key_results[0])
- (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
- (E-P0001-ca4a00b5cf) On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples. Yao2022React (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0001#key_results[0])
- (E-P0090-1d5f67b08e) Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Ghose2025Orfs (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0090#key_results[0])
- (E-P0158-895b04aa5c) Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Xi2026Toolgym (provenance: paper_notes | papers/paper_notes.jsonl:paper_id=P0158#key_results[0])

## Definitions / setup

- Setup: Which design choices in Agent loop and action spaces drive the major trade-offs, and how are those trade-offs measured? Scope: in-scope: Core topics directly relevant to 'Agent loop and action spaces'.. Axes: mechanism / architecture; data / training setup; evaluation protocol (datasets / metrics / human); efficiency / compute; failure modes / limitations. Song2026Envscaler Zhang2026Evoroute Xi2026Toolgym

## Claim candidates

- We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). Kim2025Bridging
- However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. Zhao2025Achieving
- To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. Liu2025Mcpagentbench
- Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift
- We benchmark four agent architectures and six LLM backends on 20 incident scenarios of increasing complexity, identifying CyberSleuth as the best-performing design. Fumero2025Cybersleuth

## Concrete comparisons

- Axis: mechanism / architecture; A: Agent frameworks / architectures: `P0149`, `P0150`, `P0158`; B: Tool-use and function calling: `P0149`, `P0158`, `P0085`. Zhang2026Evoroute Li2025Agentswift Ghose2025Orfs Xi2026Toolgym
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - A highlight: (E-P0058-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0090-1d5f67b08e) Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Ghose2025Orfs (pointer: papers/paper_notes.jsonl:paper_id=P0090#key_results[0])
  - B highlight: (E-P0158-895b04aa5c) Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Xi2026Toolgym (pointer: papers/paper_notes.jsonl:paper_id=P0158#key_results[0])
- Axis: data / training setup; A: Agent frameworks / architectures: `P0149`, `P0150`, `P0158`; B: Tool-use and function calling: `P0149`, `P0158`, `P0085`. Xi2026Toolgym Zhang2026Evoroute Ghose2025Orfs
  - A highlight: (E-P0158-895b04aa5c) Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Xi2026Toolgym (pointer: papers/paper_notes.jsonl:paper_id=P0158#key_results[0])
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - B highlight: (E-P0158-895b04aa5c) Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Xi2026Toolgym (pointer: papers/paper_notes.jsonl:paper_id=P0158#key_results[0])
  - B highlight: (E-P0090-1d5f67b08e) Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Ghose2025Orfs (pointer: papers/paper_notes.jsonl:paper_id=P0090#key_results[0])
- Axis: evaluation protocol (datasets / metrics / human); A: Agent frameworks / architectures: `P0149`, `P0150`, `P0158`; B: Tool-use and function calling: `P0149`, `P0158`, `P0085`. Li2025Agentswift Zhang2026Evoroute Liu2025Mcpagentbench Ghose2025Orfs
  - A highlight: (E-P0058-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - B highlight: (E-P0085-f7a14123f9) To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. Liu2025Mcpagentbench (pointer: papers/paper_notes.jsonl:paper_id=P0085#limitations[1])
  - B highlight: (E-P0090-1d5f67b08e) Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Ghose2025Orfs (pointer: papers/paper_notes.jsonl:paper_id=P0090#key_results[0])
- Axis: efficiency / compute; A: Agent frameworks / architectures: `P0149`, `P0150`, `P0158`; B: Tool-use and function calling: `P0149`, `P0158`, `P0085`. Zhang2026Evoroute Li2025Agentswift Ghose2025Orfs Xi2026Toolgym
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - A highlight: (E-P0058-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0090-1d5f67b08e) Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Ghose2025Orfs (pointer: papers/paper_notes.jsonl:paper_id=P0090#key_results[0])
  - B highlight: (E-P0158-895b04aa5c) Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Xi2026Toolgym (pointer: papers/paper_notes.jsonl:paper_id=P0158#key_results[0])
- Axis: failure modes / limitations; A: Agent frameworks / architectures: `P0149`, `P0150`, `P0158`; B: Tool-use and function calling: `P0149`, `P0158`, `P0085`. Zhang2026Evoroute Li2025Agentswift Ghose2025Orfs Xi2026Toolgym
  - A highlight: (E-P0150-60cc0d458f) Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$. Zhang2026Evoroute (pointer: papers/paper_notes.jsonl:paper_id=P0150#key_results[0])
  - A highlight: (E-P0058-904ba35500) Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\% over both existing automated agent search methods and manually designed agents. Li2025Agentswift (pointer: papers/paper_notes.jsonl:paper_id=P0058#key_results[0])
  - B highlight: (E-P0090-1d5f67b08e) Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Ghose2025Orfs (pointer: papers/paper_notes.jsonl:paper_id=P0090#key_results[0])
  - B highlight: (E-P0158-895b04aa5c) Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Xi2026Toolgym (pointer: papers/paper_notes.jsonl:paper_id=P0158#key_results[0])

## Evaluation protocol

- Evaluation tokens mentioned in mapped evidence: LLMs; LLM-simulated; SFT; RUC-NLPIR; EnvScaler; SkelBuilder; ScenGenerator; GAIA; EvoRoute; BrowseComp. Song2026Envscaler Zhang2026Evoroute Xi2026Toolgym Luo2025Large

## Failures / limitations

- We formalize this challenge as the \textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. Zhang2026Evoroute
- Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. Gasmi2025Bridging
- This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. Gasmi2025Bridging
- We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Gasmi2025Bridging

## Verify fields (non-blocking)

- named benchmarks/datasets used
- metrics/human-eval protocol
- compute/training/inference cost
- training data and supervision signal
- failure modes / known limitations
- baseline choices and ablation evidence
