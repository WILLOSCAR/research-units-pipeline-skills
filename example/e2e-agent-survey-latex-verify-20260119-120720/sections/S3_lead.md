This chapter fixes the boundary conditions of an LLM agent: what the loop looks like, what counts as an action, and how tools are represented and orchestrated. These interface choices are not “implementation details”; they constrain what evaluation claims are meaningful and what failure modes are even observable. A key theme is the trade-off between expressivity and control: richer action spaces and looser interfaces can unlock capability, whereas stricter contracts can improve verifiability and reduce costly failure cascades [@Yao2022React; @Dong2025Bench].

We first examine the agent loop and action spaces (what the policy can do and what feedback it receives), then focus on tool interfaces and orchestration (how actions are grounded into executable APIs, how tools are routed, and how sandboxing/permissions change risk). These two pieces interact tightly: the loop defines *when* the agent can act, while the interface defines *how* those actions map to real-world side effects and evaluation protocols [@Zhang2026Evoroute; @Lumer2025Memtool].
