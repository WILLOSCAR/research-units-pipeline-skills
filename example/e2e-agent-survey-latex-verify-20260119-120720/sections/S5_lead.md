Beyond fixed policies, modern agent systems increasingly adapt: they update prompts, revise plans, synthesize training data, or coordinate across multiple agents to improve outcomes. These adaptations can produce rapid gains, but they also raise stability and comparability challenges because the policy may change over the course of evaluation [@Zhou2025Self; @Wu2025Evolver].

We first review self-improvement and adaptation mechanisms (reflection, self-training, preference/RL signals, regression control), then multi-agent coordination patterns (roles, communication protocols, debate/refereeing, aggregation). The throughline is decision-relevance: which adaptation or coordination choice changes reliability/cost/safety under a fixed evaluation protocol, and which claims remain unclear without tighter logging and threat-model assumptions [@Chuang2025Debate; @Kale2025Reliable].
