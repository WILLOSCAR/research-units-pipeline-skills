Planning and memory are the two levers that most visibly change agent behavior over long horizons. Planning mechanisms decide *how* the system searches over action sequences (single-pass deliberation versus explicit search and verification), while memory mechanisms decide *what* information the policy can condition on (and how reliably that information reflects the environment) [@Yao2022React; @Liu2025Costbench].

We therefore split this chapter into planning/reasoning loops and memory/retrieval (RAG). The first subsection compares control-loop designs (planner/executor splits, search policies, verification) and how they trade accuracy for cost. The second contrasts memory types (ephemeral scratchpads versus persistent stores) and retrieval/write policies that shape robustness, leakage, and reproducibility in agent evaluations [@Nakano2025Guided; @Lumer2025Memtool].
